{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41206318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import neighbors\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca40256c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teager_kaiser_energy_6mean</th>\n",
       "      <th>time_corr_F8</th>\n",
       "      <th>max_cross_corr_C4</th>\n",
       "      <th>fractal_katz</th>\n",
       "      <th>phase_lock_val_F3</th>\n",
       "      <th>fisher_information</th>\n",
       "      <th>decorr_time</th>\n",
       "      <th>max_cross_corr_T8</th>\n",
       "      <th>max_cross_corr_P3</th>\n",
       "      <th>spect_corr_C4</th>\n",
       "      <th>...</th>\n",
       "      <th>Subj_30</th>\n",
       "      <th>Subj_31</th>\n",
       "      <th>Subj_32</th>\n",
       "      <th>Subj_33</th>\n",
       "      <th>Subj_34</th>\n",
       "      <th>Subj_35</th>\n",
       "      <th>Subj_36</th>\n",
       "      <th>Subj_37</th>\n",
       "      <th>Subj_38</th>\n",
       "      <th>Subj_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.193831</td>\n",
       "      <td>0.518370</td>\n",
       "      <td>0.469241</td>\n",
       "      <td>0.559155</td>\n",
       "      <td>0.460298</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788509</td>\n",
       "      <td>0.428153</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.414768</td>\n",
       "      <td>0.365786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467803</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.674814</td>\n",
       "      <td>0.210838</td>\n",
       "      <td>0.402709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.233510</td>\n",
       "      <td>0.546032</td>\n",
       "      <td>0.358015</td>\n",
       "      <td>0.357802</td>\n",
       "      <td>0.452609</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.660710</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.550399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.327797</td>\n",
       "      <td>0.391454</td>\n",
       "      <td>0.468610</td>\n",
       "      <td>0.503995</td>\n",
       "      <td>0.325184</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.628290</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.793829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.576995</td>\n",
       "      <td>0.108699</td>\n",
       "      <td>0.351228</td>\n",
       "      <td>0.321692</td>\n",
       "      <td>0.510215</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.519071</td>\n",
       "      <td>0.557525</td>\n",
       "      <td>0.404987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21026</th>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.492309</td>\n",
       "      <td>0.855602</td>\n",
       "      <td>0.389998</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.547843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447101</td>\n",
       "      <td>0.694548</td>\n",
       "      <td>0.807045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21027</th>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.840575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397695</td>\n",
       "      <td>0.094456</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783243</td>\n",
       "      <td>0.543601</td>\n",
       "      <td>0.493005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21028</th>\n",
       "      <td>0.050507</td>\n",
       "      <td>0.967379</td>\n",
       "      <td>0.770535</td>\n",
       "      <td>0.520693</td>\n",
       "      <td>0.070129</td>\n",
       "      <td>0.283860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189368</td>\n",
       "      <td>0.130337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21029</th>\n",
       "      <td>0.018568</td>\n",
       "      <td>0.965960</td>\n",
       "      <td>0.922056</td>\n",
       "      <td>0.413610</td>\n",
       "      <td>0.094394</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843492</td>\n",
       "      <td>0.314496</td>\n",
       "      <td>0.798449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21030</th>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.554198</td>\n",
       "      <td>0.654431</td>\n",
       "      <td>0.247069</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.669948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883667</td>\n",
       "      <td>0.034941</td>\n",
       "      <td>0.544510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21031 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       teager_kaiser_energy_6mean  time_corr_F8  max_cross_corr_C4  \\\n",
       "0                        0.001852      0.193831           0.518370   \n",
       "1                        0.002101      0.274256           0.414768   \n",
       "2                        0.001109      0.233510           0.546032   \n",
       "3                        0.006222      0.327797           0.391454   \n",
       "4                        0.001921      0.576995           0.108699   \n",
       "...                           ...           ...                ...   \n",
       "21026                    0.014841      0.492309           0.855602   \n",
       "21027                    0.013717      0.840575           0.000000   \n",
       "21028                    0.050507      0.967379           0.770535   \n",
       "21029                    0.018568      0.965960           0.922056   \n",
       "21030                    0.016807      0.554198           0.654431   \n",
       "\n",
       "       fractal_katz  phase_lock_val_F3  fisher_information  decorr_time  \\\n",
       "0          0.469241           0.559155            0.460298          0.2   \n",
       "1          0.365786           0.000000            0.467803          0.4   \n",
       "2          0.358015           0.357802            0.452609          0.4   \n",
       "3          0.468610           0.503995            0.325184          0.4   \n",
       "4          0.351228           0.321692            0.510215          0.4   \n",
       "...             ...                ...                 ...          ...   \n",
       "21026      0.389998           0.121597            0.547843          0.0   \n",
       "21027      0.397695           0.094456            0.470511          0.0   \n",
       "21028      0.520693           0.070129            0.283860          0.0   \n",
       "21029      0.413610           0.094394            0.480124          0.0   \n",
       "21030      0.247069           0.018223            0.669948          0.0   \n",
       "\n",
       "       max_cross_corr_T8  max_cross_corr_P3  spect_corr_C4  ...  Subj_30  \\\n",
       "0               0.788509           0.428153       0.289757  ...      0.0   \n",
       "1               0.674814           0.210838       0.402709  ...      0.0   \n",
       "2               0.660710           0.080080       0.550399  ...      0.0   \n",
       "3               0.628290           0.153154       0.793829  ...      0.0   \n",
       "4               0.519071           0.557525       0.404987  ...      0.0   \n",
       "...                  ...                ...            ...  ...      ...   \n",
       "21026           0.447101           0.694548       0.807045  ...      0.0   \n",
       "21027           0.783243           0.543601       0.493005  ...      0.0   \n",
       "21028           0.000000           0.189368       0.130337  ...      0.0   \n",
       "21029           0.843492           0.314496       0.798449  ...      0.0   \n",
       "21030           0.883667           0.034941       0.544510  ...      0.0   \n",
       "\n",
       "       Subj_31  Subj_32  Subj_33  Subj_34  Subj_35  Subj_36  Subj_37  Subj_38  \\\n",
       "0          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4          0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "21026      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "21027      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "21028      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "21029      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "21030      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       Subj_39  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "21026      1.0  \n",
       "21027      1.0  \n",
       "21028      1.0  \n",
       "21029      1.0  \n",
       "21030      1.0  \n",
       "\n",
       "[21031 rows x 265 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = pd.read_csv('features_tree_one_hot.csv')\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd582e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_all.loc[(data_all['film'] == 42)].reset_index(drop=True)\n",
    "\n",
    "X_train = data_all.loc[(data_all['film'] != 42)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5768a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.sample(frac=1)\n",
    "X_test = X_test.sample(frac=1)\n",
    "\n",
    "y_train = X_train['labels']\n",
    "y_test = X_test['labels']\n",
    "\n",
    "train_film = X_train['film']\n",
    "train_subj = X_train['Subj']\n",
    "train_ch = X_train['ch']\n",
    "test_film = X_test['film']\n",
    "test_subj = X_test['Subj']\n",
    "test_ch = X_test['ch']\n",
    "X_train = X_train.drop(['labels', 'ch', 'Subj', 'film'], axis=1)\n",
    "X_test = X_test.drop(['labels', 'ch', 'Subj', 'film'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f838c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f3a544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qt_train = QuantileTransformer(output_distribution='normal', copy=True)\n",
    "y_train = pd.DataFrame(qt_train.fit_transform(np.array(y_train).reshape(-1, 1)))\n",
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4100003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b880d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\po6wi\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (82). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qt_test = QuantileTransformer(output_distribution='normal', copy=True)\n",
    "y_test = pd.DataFrame(qt_test.fit_transform(np.array(y_test).reshape(-1, 1)))\n",
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a18e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247d157e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}],\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "searcher = GridSearchCV(Ridge(), [{\"alpha\": alphas}], scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bb5a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_params_[\"alpha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62dc93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(searcher.best_params_[\"alpha\"]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "825683fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9afcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f44c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a301d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_inv = qt_test.inverse_transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3246242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44090396969885237\n",
      "0.23763898690023935\n",
      "1.271621773390073\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test_inv, preds))\n",
    "print(mean_absolute_percentage_error(y_test_inv, preds))\n",
    "print(mean_absolute_error(y_test_inv ,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f968a",
   "metadata": {},
   "source": [
    "## Усреднение оценок по каналам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c039e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-a9645642cf24>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
      "<ipython-input-21-a9645642cf24>:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
      "<ipython-input-21-a9645642cf24>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
      "<ipython-input-21-a9645642cf24>:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n"
     ]
    }
   ],
   "source": [
    "pred = [[0 for j in range(8)] for i in range(42)]\n",
    "num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "labels = [[0 for j in range(8)] for i in range(42)]\n",
    "lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "for i in range(len(preds)):\n",
    "    pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "    num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "    labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "labels = np.nan_to_num(labels)\n",
    "pred = np.nan_to_num(pred)\n",
    "predicted = []\n",
    "lbl = []\n",
    "for i in range(len(labels)):\n",
    "    if sum(labels[i]) != 0:\n",
    "        for j in range(4):\n",
    "            if labels[i][j] != 0:\n",
    "                lbl.append(labels[i][j])  \n",
    "                predicted.append(pred[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00444a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 6.520475923607427\n",
      "8.0 7.884917184138755\n",
      "3.0 3.01238906562072\n",
      "6.0 5.116410086325303\n",
      "2.0 3.5\n",
      "7.0 3.0\n",
      "4.0 5.917225046569353\n"
     ]
    }
   ],
   "source": [
    "for [l, p] in zip(lbl, predicted):\n",
    "    print(l, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "486a793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2954081546395164\n",
      "0.33063818097793035\n",
      "1.7011158454455126\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(lbl, predicted))\n",
    "print(mean_absolute_percentage_error(lbl, predicted))\n",
    "print(mean_absolute_error(lbl ,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bdf1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e8e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax1 = plt.subplots(sharey=True, figsize=(15,8))\n",
    "\n",
    "ax1.scatter(lbl, predicted)\n",
    "ax1.plot([0, 10], [0, 10], '--k')\n",
    "ax1.set_ylabel('Target predicted')\n",
    "ax1.set_xlabel('True Target')\n",
    "\n",
    "f.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa478a0",
   "metadata": {},
   "source": [
    "## Перебор всех фильмов и моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "AVERAGE_MAE = 0\n",
    "AVERAGE_MAPE = 0\n",
    "AVERAGE_R2 = 0\n",
    "BEST_MODELS_MAE = []\n",
    "BEST_MODELS_MAPE = []\n",
    "BEST_MODELS_R2 = []\n",
    "MIN_MAE = np.inf\n",
    "MIN_MAPE = np.inf\n",
    "MAX_R2 = -np.inf\n",
    "MAX_MAE = -np.inf\n",
    "MAX_MAPE = -np.inf\n",
    "MIN_R2 = np.inf\n",
    "chans = ['Fz', 'F3', 'F7','C3', 'T7', 'Pz', 'P3','P7', 'O1', 'Oz', 'O2','P4', 'P8', 'Cz','C4', 'T8', 'F4', 'F8']\n",
    "for film in tqdm_notebook(range(41, 49)):\n",
    "    best = []\n",
    "    best_features = []\n",
    "    print('Testing for ', film - 40 , 'film')\n",
    "    X_test = data_all.loc[(data_all['film'] == film)].reset_index(drop=True)\n",
    "    X_train = data_all.loc[(data_all['film'] != film)].reset_index(drop=True)\n",
    "    X_train = X_train.sample(frac=1)\n",
    "    X_test = X_test.sample(frac=1)\n",
    "\n",
    "    y_train = X_train['labels']\n",
    "    y_test_inv = np.array(X_test['labels'])\n",
    "    train_film = X_train['film']\n",
    "    train_subj = X_train['Subj']\n",
    "    train_ch = X_train['ch']\n",
    "    test_film = X_test['film']\n",
    "    test_subj = X_test['Subj']\n",
    "    test_ch = np.array(X_test['ch'])\n",
    "    X_train = X_train.drop(['labels'], axis=1)\n",
    "    X_test = X_test.drop(['labels'], axis=1)\n",
    "    \n",
    "    X_train = X_train.drop(['film', 'ch', 'Subj'], axis=1)\n",
    "    X_test = X_test.drop(['film', 'ch', 'Subj'], axis=1)\n",
    "    \n",
    "    qt_train = QuantileTransformer(output_distribution='normal',\n",
    "                             copy=True)\n",
    "    y_train = pd.DataFrame(qt_train.fit_transform(np.array(y_train).reshape(-1, 1)))\n",
    "    qt_test = QuantileTransformer(output_distribution='normal',\n",
    "                             copy=True)\n",
    "    y_test = pd.DataFrame(qt_test.fit_transform(np.array(y_test_inv).reshape(-1, 1)))\n",
    "    \n",
    "    SKB = SelectKBest(score_func=f_regression, k=100)\n",
    "    X_new = SKB.fit_transform(X_train, y_train)\n",
    "    indices = SKB.get_support(indices=True)\n",
    "    selected_features = [X_train.columns[indices[i]] for i in range(len(indices))]\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    print('selected features by SKB: ', selected_features)\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    print('Ridge')\n",
    "    alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    searcher = GridSearchCV(Ridge(), [{\"alpha\": alphas}], scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "    searcher.fit(X_train, y_train)\n",
    "    print('Ridge alpha', searcher.best_params_[\"alpha\"])\n",
    "    model = Ridge(searcher.best_params_[\"alpha\"]).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Ridge r2:', r2_score(y_test, y_pred))\n",
    "    print('Ridge MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('Ridge MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(y_pred)\n",
    "    print('Ridge inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('Ridge inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('Ridge inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('Ridge inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('Ridge inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('Ridge inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'Ridge'})\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ElasticNet')\n",
    "    model = ElasticNet(alpha=0.001, l1_ratio=1).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('ElasticNet r2:', r2_score(y_test, y_pred))\n",
    "    print('ElasticNet MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('ElasticNet MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    print('ElasticNet inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('ElasticNet inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('ElasticNet inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('ElasticNet inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('ElasticNet inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('ElasticNet inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'ElasticNet'})\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('LinearRegression')\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('LinearRegression r2:', r2_score(y_test, y_pred))\n",
    "    print('LinearRegression MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('LinearRegression MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    print('LinearRegression inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('LinearRegression inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('LinearRegression inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('LinearRegression inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('LinearRegression inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('LinearRegression inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'LinearRegression'})\n",
    "\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "    print('-----------------------------------------------------------------')\n",
    "    \n",
    "    print('Lasso')\n",
    "    alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    param_grid = dict(alpha=alpha)\n",
    "    grid = GridSearchCV(estimator=Lasso(), param_grid=param_grid, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model = Lasso(grid.best_params_[\"alpha\"]).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Lasso r2:', r2_score(y_test, y_pred))\n",
    "    print('Lasso MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('Lasso MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    print('Lasso inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('Lasso inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('Lasso inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('Lasso inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('Lasso inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('Lasso inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'Lasso'})\n",
    "\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('DecisionTreeRegressor')\n",
    "    model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('DecisionTreeRegressor r2:', r2_score(y_test, y_pred))\n",
    "    print('DecisionTreeRegressor MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('DecisionTreeRegressor MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    print('DecisionTreeRegressor inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('DecisionTreeRegressor inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('DecisionTreeRegressor inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('DecisionTreeRegressor inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('DecisionTreeRegressor inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('DecisionTreeRegressor inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'DecisionTreeRegressor'})\n",
    "\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('MLPRegressor')\n",
    "    model = MLPRegressor(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('MLPRegressor r2:', r2_score(y_test, y_pred))\n",
    "    print('MLPRegressor MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('MLPRegressor MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    print('MLPRegressor inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('MLPRegressor inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('MLPRegressor inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('MLPRegressor inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('MLPRegressor inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('MLPRegressor inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'MLPRegressor'})\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('KNeighborsRegressor')\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors=500).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('KNeighborsRegressor r2:', r2_score(y_test, y_pred))\n",
    "    print('KNeighborsRegressor MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print('KNeighborsRegressor MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    print('KNeighborsRegressor inverted r2:', r2_score(preds, y_test_inv))\n",
    "    print('KNeighborsRegressor inverted MAPE: ', mean_absolute_percentage_error(preds, y_test_inv))\n",
    "    print('KNeighborsRegressor inverted MAE: ', mean_absolute_error(preds, y_test_inv))\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    print('KNeighborsRegressor inverted by film r2:', r2_score(lbl, predicted))\n",
    "    print('KNeighborsRegressor inverted by film MAPE:', mean_absolute_percentage_error(lbl, predicted))\n",
    "    print('KNeighborsRegressor inverted by film MAE:', mean_absolute_error(lbl ,predicted))\n",
    "    best.append({'MAE' : mean_absolute_error(lbl ,predicted), 'MAPE' : mean_absolute_percentage_error(lbl, predicted), 'r2' : r2_score(lbl, predicted) , 'model' : 'KNeighborsRegressor'})\n",
    "    for [l, p] in zip(lbl, predicted):\n",
    "        print('label : {:0.2f} predicted: {:0.2f} '.format(l, p))\n",
    "    for i in range(33, len(channels)):\n",
    "        print('predictions by channel', channels[i])\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print('Best model by MAE', sorted(best, key=lambda x: x['MAE'])[0]['model'])\n",
    "    print('MAE', sorted(best, key=lambda x: x['MAE'])[0]['MAE'])\n",
    "    print('MAPE', sorted(best, key=lambda x: x['MAE'])[0]['MAPE'])\n",
    "    print('R2', sorted(best, key=lambda x: x['MAE'])[0]['r2'])\n",
    "    BEST_MODELS_MAE.append(sorted(best, key=lambda x: x['MAE'])[0]['model'])\n",
    "    print('Best model by MAPE', sorted(best, key=lambda x: x['MAPE'])[0]['model'])\n",
    "    print('MAE', sorted(best, key=lambda x: x['MAPE'])[0]['MAE'])\n",
    "    print('MAPE', sorted(best, key=lambda x: x['MAPE'])[0]['MAPE'])\n",
    "    print('R2', sorted(best, key=lambda x: x['MAPE'])[0]['r2'])\n",
    "    BEST_MODELS_MAPE.append(sorted(best, key=lambda x: x['MAPE'])[0]['model'])\n",
    "    print('Best model by R2', sorted(best, key=lambda x: x['r2'], reverse=True)[0]['model'])\n",
    "    print('MAE', sorted(best, key=lambda x: x['r2'], reverse=True)[0]['MAE'])\n",
    "    print('MAPE', sorted(best, key=lambda x: x['r2'], reverse=True)[0]['MAPE'])\n",
    "    print('R2', sorted(best, key=lambda x: x['r2'], reverse=True)[0]['r2'])\n",
    "    BEST_MODELS_R2.append(sorted(best, key=lambda x: x['r2'], reverse=True)[0]['model'])\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    AVERAGE_MAE += sorted(best, key=lambda x: x['MAE'])[0]['MAE']\n",
    "    AVERAGE_MAPE += sorted(best, key=lambda x: x['MAPE'])[0]['MAPE']\n",
    "    AVERAGE_R2 += sorted(best, key=lambda x: x['r2'], reverse=True)[0]['r2']\n",
    "    MIN_MAE = min(MIN_MAE, sorted(best, key=lambda x: x['MAE'])[0]['MAE'])\n",
    "    MIN_MAPE = min(MIN_MAPE, sorted(best, key=lambda x: x['MAPE'])[0]['MAPE'])\n",
    "    MIN_R2 = min(MIN_R2, sorted(best, key=lambda x: x['r2'], reverse=True)[0]['r2'])\n",
    "    MAX_MAE = max(MAX_MAE, sorted(best, key=lambda x: x['MAE'])[0]['MAE'])\n",
    "    MAX_MAPE = max(MAX_MAPE, sorted(best, key=lambda x: x['MAPE'])[0]['MAPE'])\n",
    "    MAX_R2 = max(MAX_R2, sorted(best, key=lambda x: x['r2'], reverse=True)[0]['r2'])\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "AVERAGE_MAE /= 8\n",
    "AVERAGE_MAPE /= 8\n",
    "AVERAGE_R2 /= 8\n",
    "print('AVERAGE INFO : MAE {:0.2f}, MAPE {:0.2f}, R2 {:0.2f}'.format(AVERAGE_MAE,AVERAGE_MAPE, AVERAGE_R2))\n",
    "print('MIN MAE {:0.2f}, MIN MAPE {:0.2f}, MIN R2 {:0.2f}, MAX MAE {:0.2f}, MAX MAPE {:0.2f}, MAX R2 {:0.2f}'.format(MIN_MAE, MIN_MAPE, MIN_R2, MAX_MAE, MAX_MAPE, MAX_R2))\n",
    "print('Best models')\n",
    "print('By MAE: ', *BEST_MODELS_MAE)\n",
    "print('By MAPE: ', *BEST_MODELS_MAPE)\n",
    "print('By R2: ', *BEST_MODELS_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c09c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output in .txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('minmax_full_factor_3.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848a40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Ridge', 'ElasticNet', 'LinearRegression', 'Lasso', 'DecisionTreeRegressor', 'MLPRegressor', 'KNeighborsRegressor']\n",
    "metrics = ['MAPE', 'MAE', 'R2']\n",
    "formes = ['inverted', 'average']\n",
    "columns = [\n",
    "    np.array([models[i] for i in range(7) for j in range(3) for k in range(2)]),\n",
    "    np.array([metrics[j] for i in range(7) for j in range(3) for k in range(2)]),\n",
    "    np.array([formes[k] for i in range(7) for j in range(3) for k in range(2)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d7a626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Ridge', 'Ridge', 'Ridge', 'Ridge', 'Ridge', 'Ridge', 'ElasticNet',\n",
       "        'ElasticNet', 'ElasticNet', 'ElasticNet', 'ElasticNet',\n",
       "        'ElasticNet', 'LinearRegression', 'LinearRegression',\n",
       "        'LinearRegression', 'LinearRegression', 'LinearRegression',\n",
       "        'LinearRegression', 'Lasso', 'Lasso', 'Lasso', 'Lasso', 'Lasso',\n",
       "        'Lasso', 'DecisionTreeRegressor', 'DecisionTreeRegressor',\n",
       "        'DecisionTreeRegressor', 'DecisionTreeRegressor',\n",
       "        'DecisionTreeRegressor', 'DecisionTreeRegressor', 'MLPRegressor',\n",
       "        'MLPRegressor', 'MLPRegressor', 'MLPRegressor', 'MLPRegressor',\n",
       "        'MLPRegressor', 'KNeighborsRegressor', 'KNeighborsRegressor',\n",
       "        'KNeighborsRegressor', 'KNeighborsRegressor',\n",
       "        'KNeighborsRegressor', 'KNeighborsRegressor'], dtype='<U21'),\n",
       " array(['MAPE', 'MAPE', 'MAE', 'MAE', 'R2', 'R2', 'MAPE', 'MAPE', 'MAE',\n",
       "        'MAE', 'R2', 'R2', 'MAPE', 'MAPE', 'MAE', 'MAE', 'R2', 'R2',\n",
       "        'MAPE', 'MAPE', 'MAE', 'MAE', 'R2', 'R2', 'MAPE', 'MAPE', 'MAE',\n",
       "        'MAE', 'R2', 'R2', 'MAPE', 'MAPE', 'MAE', 'MAE', 'R2', 'R2',\n",
       "        'MAPE', 'MAPE', 'MAE', 'MAE', 'R2', 'R2'], dtype='<U4'),\n",
       " array(['inverted', 'average', 'inverted', 'average', 'inverted',\n",
       "        'average', 'inverted', 'average', 'inverted', 'average',\n",
       "        'inverted', 'average', 'inverted', 'average', 'inverted',\n",
       "        'average', 'inverted', 'average', 'inverted', 'average',\n",
       "        'inverted', 'average', 'inverted', 'average', 'inverted',\n",
       "        'average', 'inverted', 'average', 'inverted', 'average',\n",
       "        'inverted', 'average', 'inverted', 'average', 'inverted',\n",
       "        'average', 'inverted', 'average', 'inverted', 'average',\n",
       "        'inverted', 'average'], dtype='<U8')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c57f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a5f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"np\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e9ecd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017801c4feb14abc940e575849abfb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chans = ['Fz', 'F3', 'F7','C3', 'T7', 'Pz', 'P3','P7', 'O1', 'Oz', 'O2','P4', 'P8', 'Cz','C4', 'T8', 'F4', 'F8']\n",
    "result = pd.DataFrame()\n",
    "for film in tqdm_notebook(range(41, 49)):\n",
    "    df = pd.DataFrame(np.random.randn(1, 7 * 3 * 2), columns=columns)\n",
    "    X_test = data_all.loc[(data_all['film'] == film)].reset_index(drop=True)\n",
    "    X_train = data_all.loc[(data_all['film'] != film)].reset_index(drop=True)\n",
    "    X_train = X_train.sample(frac=1)\n",
    "    X_test = X_test.sample(frac=1)\n",
    "\n",
    "    y_train = X_train['labels']\n",
    "    y_test_inv = np.array(X_test['labels'])\n",
    "    train_film = X_train['film']\n",
    "    train_subj = X_train['Subj']\n",
    "    train_ch = X_train['ch']\n",
    "    test_film = X_test['film']\n",
    "    test_subj = X_test['Subj']\n",
    "    test_ch = np.array(X_test['ch'])\n",
    "    X_train = X_train.drop(['labels'], axis=1)\n",
    "    X_test = X_test.drop(['labels'], axis=1)\n",
    "    \n",
    "    X_train = X_train.drop(['film', 'ch', 'Subj'], axis=1)\n",
    "    X_test = X_test.drop(['film', 'ch', 'Subj'], axis=1)\n",
    "    \n",
    "    qt_train = QuantileTransformer(output_distribution='normal',\n",
    "                             copy=True)\n",
    "    y_train = pd.DataFrame(qt_train.fit_transform(np.array(y_train).reshape(-1, 1)))\n",
    "    qt_test = QuantileTransformer(output_distribution='normal',\n",
    "                             copy=True)\n",
    "    y_test = pd.DataFrame(qt_test.fit_transform(np.array(y_test_inv).reshape(-1, 1)))\n",
    "    \n",
    "    model = Ridge(alpha=0.001, max_iter=1000).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(y_pred)\n",
    "    df[('Ridge', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('Ridge', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('Ridge', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "\n",
    "    df[('Ridge', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('Ridge', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('Ridge', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "    \n",
    "\n",
    "    model = ElasticNet(alpha=0.001, l1_ratio=1, max_iter=1000).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    df[('ElasticNet', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('ElasticNet', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('ElasticNet', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    df[('ElasticNet', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('ElasticNet', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('ElasticNet', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "    \n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    df[('LinearRegression', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('LinearRegression', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('LinearRegression', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    df[('LinearRegression', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('LinearRegression', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('LinearRegression', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "\n",
    "    alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    param_grid = dict(alpha=alpha)\n",
    "    grid = GridSearchCV(estimator=Lasso(), param_grid=param_grid, cv=[(slice(None), slice(None))])\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model = Lasso(grid.best_params_[\"alpha\"]).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    df[('Lasso', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('Lasso', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('Lasso', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    df[('Lasso', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('Lasso', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('Lasso', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "    \n",
    "    model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    df[('DecisionTreeRegressor', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('DecisionTreeRegressor', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('DecisionTreeRegressor', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    df[('DecisionTreeRegressor', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('DecisionTreeRegressor', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('DecisionTreeRegressor', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "\n",
    "    model = MLPRegressor(random_state=1, max_iter=1000, alpha=0.001).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    df[('MLPRegressor', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('MLPRegressor', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('MLPRegressor', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "\n",
    "    df[('MLPRegressor', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('MLPRegressor', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('MLPRegressor', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "\n",
    "    n_neighbors = [100, 300, 500, 1000]\n",
    "    param_grid = dict(n_neighbors=n_neighbors)\n",
    "    grid = GridSearchCV(estimator=neighbors.KNeighborsRegressor(), param_grid=param_grid, cv=[(slice(None), slice(None))])\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors=grid.best_params_['n_neighbors']).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds = qt_test.inverse_transform(np.array(y_pred).reshape(-1, 1))\n",
    "    df[('KNeighborsRegressor', 'R2', 'inverted')] = r2_score(preds, y_test_inv)\n",
    "    df[('KNeighborsRegressor', 'MAPE', 'inverted')] = mean_absolute_percentage_error(preds, y_test_inv)\n",
    "    df[('KNeighborsRegressor', 'MAE', 'inverted')] = mean_absolute_error(preds, y_test_inv)\n",
    "    \n",
    "    pred = [[0 for j in range(8)] for i in range(42)]\n",
    "    num_chans = [[0 for j in range(8)] for i in range(42)]\n",
    "    labels = [[0 for j in range(8)] for i in range(42)]\n",
    "    lbl = [[0 for j in range(8)] for i in range(42)]\n",
    "    channels = [[] for i in range(40)]\n",
    "    for i in range(len(preds)):\n",
    "        pred[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += preds[i]\n",
    "        num_chans[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += 1\n",
    "        labels[np.array(test_subj)[i]][np.array(test_film)[i] - 41] += y_test_inv[i]\n",
    "        channels[np.array(test_subj)[i]].append(chans[test_ch[i]])\n",
    "    labels = np.array(labels).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    pred = np.array(pred).astype(np.float64) / np.array(num_chans).astype(np.float64)\n",
    "    labels = np.nan_to_num(labels)\n",
    "    pred = np.nan_to_num(pred)\n",
    "    predicted = []\n",
    "    lbl = []\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i]) != 0:\n",
    "            for j in range(8):\n",
    "                if labels[i][j] != 0:\n",
    "                    lbl.append(labels[i][j])  \n",
    "                    predicted.append(pred[i][j])\n",
    "    df[('KNeighborsRegressor', 'R2', 'average')] = r2_score(lbl, predicted)\n",
    "    df[('KNeighborsRegressor', 'MAPE', 'average')] = mean_absolute_percentage_error(lbl, predicted)\n",
    "    df[('KNeighborsRegressor', 'MAE', 'average')] = mean_absolute_error(lbl, predicted)\n",
    "    result = pd.concat([result, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0833316",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.index = [i for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463ac1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Ridge</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ElasticNet</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MLPRegressor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">KNeighborsRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAPE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MAE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>...</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "      <th>inverted</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162450</td>\n",
       "      <td>0.378881</td>\n",
       "      <td>1.504673</td>\n",
       "      <td>1.842971</td>\n",
       "      <td>-6.454206</td>\n",
       "      <td>-0.037695</td>\n",
       "      <td>0.099247</td>\n",
       "      <td>0.267361</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>1.136909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364719</td>\n",
       "      <td>0.368441</td>\n",
       "      <td>0.805660</td>\n",
       "      <td>0.944306</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>0.350385</td>\n",
       "      <td>1.058575</td>\n",
       "      <td>1.492653</td>\n",
       "      <td>-4.240581</td>\n",
       "      <td>0.102751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.306435</td>\n",
       "      <td>0.304953</td>\n",
       "      <td>1.592687</td>\n",
       "      <td>1.605884</td>\n",
       "      <td>0.280016</td>\n",
       "      <td>0.483936</td>\n",
       "      <td>0.316339</td>\n",
       "      <td>0.396013</td>\n",
       "      <td>1.740313</td>\n",
       "      <td>1.755016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>1.418445</td>\n",
       "      <td>0.587709</td>\n",
       "      <td>0.574907</td>\n",
       "      <td>0.394074</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>2.450194</td>\n",
       "      <td>2.473297</td>\n",
       "      <td>-4.849436</td>\n",
       "      <td>-0.119285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.304719</td>\n",
       "      <td>0.803189</td>\n",
       "      <td>1.973403</td>\n",
       "      <td>1.990495</td>\n",
       "      <td>-3.286557</td>\n",
       "      <td>-1.692463</td>\n",
       "      <td>0.476691</td>\n",
       "      <td>0.685468</td>\n",
       "      <td>1.856069</td>\n",
       "      <td>1.859150</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363923</td>\n",
       "      <td>1.379068</td>\n",
       "      <td>-0.758615</td>\n",
       "      <td>-0.772646</td>\n",
       "      <td>0.288201</td>\n",
       "      <td>0.598342</td>\n",
       "      <td>1.528902</td>\n",
       "      <td>1.540734</td>\n",
       "      <td>-7.304156</td>\n",
       "      <td>-0.558679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304871</td>\n",
       "      <td>1.531396</td>\n",
       "      <td>2.577365</td>\n",
       "      <td>3.108611</td>\n",
       "      <td>-11.889435</td>\n",
       "      <td>-1.002004</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>1.037337</td>\n",
       "      <td>2.509705</td>\n",
       "      <td>2.708598</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224790</td>\n",
       "      <td>3.380222</td>\n",
       "      <td>-2.011676</td>\n",
       "      <td>-0.858139</td>\n",
       "      <td>0.306830</td>\n",
       "      <td>1.322430</td>\n",
       "      <td>2.440367</td>\n",
       "      <td>2.866013</td>\n",
       "      <td>-7.634921</td>\n",
       "      <td>-0.564822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.229688</td>\n",
       "      <td>0.344741</td>\n",
       "      <td>1.944444</td>\n",
       "      <td>1.846154</td>\n",
       "      <td>-4.606645</td>\n",
       "      <td>-0.983902</td>\n",
       "      <td>0.168479</td>\n",
       "      <td>0.197664</td>\n",
       "      <td>1.206945</td>\n",
       "      <td>1.278572</td>\n",
       "      <td>...</td>\n",
       "      <td>1.323955</td>\n",
       "      <td>1.327163</td>\n",
       "      <td>-0.426383</td>\n",
       "      <td>-0.100824</td>\n",
       "      <td>0.218553</td>\n",
       "      <td>0.273948</td>\n",
       "      <td>1.629898</td>\n",
       "      <td>1.580996</td>\n",
       "      <td>-2.154497</td>\n",
       "      <td>-0.109355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.244470</td>\n",
       "      <td>0.463340</td>\n",
       "      <td>1.870637</td>\n",
       "      <td>1.920996</td>\n",
       "      <td>-2.011293</td>\n",
       "      <td>-0.135185</td>\n",
       "      <td>0.170538</td>\n",
       "      <td>0.298627</td>\n",
       "      <td>1.179688</td>\n",
       "      <td>1.224857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177496</td>\n",
       "      <td>1.160413</td>\n",
       "      <td>-0.044924</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>0.229178</td>\n",
       "      <td>0.437560</td>\n",
       "      <td>1.577046</td>\n",
       "      <td>1.720196</td>\n",
       "      <td>-4.258101</td>\n",
       "      <td>0.105971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.314832</td>\n",
       "      <td>0.637868</td>\n",
       "      <td>2.247706</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>-3.737912</td>\n",
       "      <td>-1.263971</td>\n",
       "      <td>0.384013</td>\n",
       "      <td>0.524845</td>\n",
       "      <td>2.158659</td>\n",
       "      <td>2.272136</td>\n",
       "      <td>...</td>\n",
       "      <td>2.314918</td>\n",
       "      <td>2.612065</td>\n",
       "      <td>-1.594193</td>\n",
       "      <td>-1.574333</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>0.463189</td>\n",
       "      <td>1.761396</td>\n",
       "      <td>1.819266</td>\n",
       "      <td>-3.336532</td>\n",
       "      <td>-0.229788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.340557</td>\n",
       "      <td>0.929879</td>\n",
       "      <td>2.737687</td>\n",
       "      <td>2.717115</td>\n",
       "      <td>-3.642973</td>\n",
       "      <td>-0.626802</td>\n",
       "      <td>0.176931</td>\n",
       "      <td>0.391887</td>\n",
       "      <td>0.893917</td>\n",
       "      <td>0.874897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576062</td>\n",
       "      <td>0.557905</td>\n",
       "      <td>0.745254</td>\n",
       "      <td>0.864168</td>\n",
       "      <td>0.239611</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>1.628487</td>\n",
       "      <td>1.608292</td>\n",
       "      <td>-1.743649</td>\n",
       "      <td>0.058232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ridge                                                    ElasticNet  \\\n",
       "       MAPE                 MAE                   R2                 MAPE   \n",
       "   inverted   average  inverted   average   inverted   average   inverted   \n",
       "1  0.162450  0.378881  1.504673  1.842971  -6.454206 -0.037695   0.099247   \n",
       "2  0.306435  0.304953  1.592687  1.605884   0.280016  0.483936   0.316339   \n",
       "3  0.304719  0.803189  1.973403  1.990495  -3.286557 -1.692463   0.476691   \n",
       "4  0.304871  1.531396  2.577365  3.108611 -11.889435 -1.002004   0.360104   \n",
       "5  0.229688  0.344741  1.944444  1.846154  -4.606645 -0.983902   0.168479   \n",
       "6  0.244470  0.463340  1.870637  1.920996  -2.011293 -0.135185   0.170538   \n",
       "7  0.314832  0.637868  2.247706  2.277778  -3.737912 -1.263971   0.384013   \n",
       "8  0.340557  0.929879  2.737687  2.717115  -3.642973 -0.626802   0.176931   \n",
       "\n",
       "                                 ... MLPRegressor                      \\\n",
       "                  MAE            ...          MAE                  R2   \n",
       "    average  inverted   average  ...     inverted   average  inverted   \n",
       "1  0.267361  0.792999  1.136909  ...     0.364719  0.368441  0.805660   \n",
       "2  0.396013  1.740313  1.755016  ...     1.392986  1.418445  0.587709   \n",
       "3  0.685468  1.856069  1.859150  ...     1.363923  1.379068 -0.758615   \n",
       "4  1.037337  2.509705  2.708598  ...     3.224790  3.380222 -2.011676   \n",
       "5  0.197664  1.206945  1.278572  ...     1.323955  1.327163 -0.426383   \n",
       "6  0.298627  1.179688  1.224857  ...     1.177496  1.160413 -0.044924   \n",
       "7  0.524845  2.158659  2.272136  ...     2.314918  2.612065 -1.594193   \n",
       "8  0.391887  0.893917  0.874897  ...     0.576062  0.557905  0.745254   \n",
       "\n",
       "            KNeighborsRegressor                                          \\\n",
       "                           MAPE                 MAE                  R2   \n",
       "    average            inverted   average  inverted   average  inverted   \n",
       "1  0.944306            0.124444  0.350385  1.058575  1.492653 -4.240581   \n",
       "2  0.574907            0.394074  0.717500  2.450194  2.473297 -4.849436   \n",
       "3 -0.772646            0.288201  0.598342  1.528902  1.540734 -7.304156   \n",
       "4 -0.858139            0.306830  1.322430  2.440367  2.866013 -7.634921   \n",
       "5 -0.100824            0.218553  0.273948  1.629898  1.580996 -2.154497   \n",
       "6  0.389567            0.229178  0.437560  1.577046  1.720196 -4.258101   \n",
       "7 -1.574333            0.295072  0.463189  1.761396  1.819266 -3.336532   \n",
       "8  0.864168            0.239611  0.708628  1.628487  1.608292 -1.743649   \n",
       "\n",
       "             \n",
       "             \n",
       "    average  \n",
       "1  0.102751  \n",
       "2 -0.119285  \n",
       "3 -0.558679  \n",
       "4 -0.564822  \n",
       "5 -0.109355  \n",
       "6  0.105971  \n",
       "7 -0.229788  \n",
       "8  0.058232  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0843ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('metrics_all_tree.xlsx', engine='xlsxwriter')\n",
    "result.to_excel(writer, sheet_name='metrics_all_tree')\n",
    "writer.sheets['metrics_all_tree'].set_row(3, None, None, {'hidden': True})\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22174ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
